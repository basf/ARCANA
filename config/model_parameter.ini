[model_settings]
; The number of features in the input data
input_size =
; The number of features in the output data
output_size =
; The type of loss function to be used
loss_type = ; Options: "pinball", "combinedhp", "huber"
; The importance weights for the dimensions in the loss function
dim_weights =
; The minimum length of input sequences
minimum_cycle_length =
; The maximum length of input sequences
maximum_cycle_length =
; Path to the tuning configuration file
path_to_tuning_config =

[huber_loss]
; The delta value for Huber loss
beta =
; The reduction parameter for the loss function
reduction = ;

[quantile_loss]
; The quantile for the quantile loss function
delta =

[optimizer]
; The learning rate for the optimizer
learning_rate =
; The weight decay regularization term
weight_decay =

[scheduler_reduced]
; The factor by which the learning rate is reduced
factor_reduced =

[scheduler_cycle]
; The number of epochs for the step size up phase
step_size_up =

[model_parameters]
; The number of training epochs
number_of_epochs =
; The dimensionality of the hidden state in the LSTM
hidden_dim =
; The batch size for training
batch_size =
; Whether the LSTM is bidirectional
bidirectional =
; The dropout rate for the output layer
output_dropout =
; The length of the window for input sequences
window_length =
; The number of warmup steps for learning rate scheduling
warmup_steps =

[encoder]
; The dropout rate for the encoder
dropout_encoder =
; The number of layers in the encoder LSTM
num_layers_encoder =

[decoder]
; The dropout rate for the decoder
dropout_decoder =
; The number of layers in the decoder LSTM
num_layers_decoder =

[multihead_attention]
; The number of attention heads in the encoder
nhead_encoder =
; The number of attention heads in the decoder
nhead_decoder =

[early_stopping]
; The type of early stopping to use
early_stopping_type = ; Options: e.g., "PGUP"
; The alpha value for early stopping
early_stopping_alpha =
; The patience for early stopping
patience =

[teacher_forcing]
; The starting ratio for teacher forcing
tl_start_ratio =
; The ending ratio for teacher forcing
tl_end_ratio =
; The division of epochs for adjusting teacher forcing
epoch_division =
; The stride of decay for teacher forcing ratio
decay_stride =